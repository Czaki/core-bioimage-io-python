format_version: 0.3.0

name: sklearnRandomForestClassifierBroadNucleusData
description: Random Forest Classifier form scikit-learn

authors:
  - Fynn Beuttenmueller
cite:
  - text: L. Breiman, "Random Forests", Machine Learning, 45(1), 5-32, 2001
    url: https://scikit-learn.org/stable/modules/generated/sklearnbased.ensemble.RandomForestClassifier.html

git_repo: https://github.com/bioimage-io/python-bioimage-io/tree/master/specs/models/sklearnbased
tags: [test, rf, random, forest, example]
license: MIT

documentation: sklearnbased.md
covers: []
attachments: {}

inputs:
  - name: raw
    description: raw input data
    axes: byx
    data_type: float32
    data_range: [-inf, inf]
    shape:
      min: [1, 96, 96]
      step: [0, 1, 1]

outputs:
  - name: probabilities
    description: probability in [0,1]
    axes: byx
    data_type: float32
    data_range: [0, 1]
    halo: [0, 32, 32]
    shape:
      reference_input: raw
      scale: [1, 1, 1]
      offset: [0, 0, 0]

language: python
framework: scikit-learn

source: pybio.sklearn.models.sklearnbased.RandomForestClassifier
kwargs:
  channel_indices: [null]
  n_estimators: 10
  criterion: gini
  max_depth: null
  min_samples_split: 2
  min_samples_leaf: 1
  min_weight_fraction_leaf: 0.0
  max_features: auto
  max_leaf_nodes: null
  min_impurity_decrease: 0.0
  bootstrap: true
  oob_score: false
  n_jobs: 1
  random_state: 0
  verbose: 0
  warm_start: false
  class_weight: null

dependencies: conda:../env_numpy.yaml
timestamp: "2020-10-23T16:00:42+00:00"

weights:
  pickle:
    id: default
    name: toy examle weights
    description: Trained as a toy example on a tiny subset of the broad nucleus data. Don't use for any real problem! (Use ilastik pixelclassification instead! ;-))
    authors: [Fynn Beuttenmueller]
    covers: []
    source: rf_v0.pickle
    sha256: abcdefghabcdefghabcdefghabcdefghabcdefghabcdefghabcdefghabcdefgh
    tags: [toy example]
    test_inputs:
      - test_input_raw.npy
    test_outputs:
      - test_output.npy
